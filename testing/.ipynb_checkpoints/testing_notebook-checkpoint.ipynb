{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting paths to folders\n",
    "import sys\n",
    "sys.path.insert(1, '../classes')\n",
    "sys.path.insert(1, '../tf_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Individual\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vals: [-0.88730201  0.15135199 -0.31454241  0.23589285 -0.23773894  0.40859426\n",
      "  0.18496516 -0.23635246  0.39524466 -0.42087081]\n",
      "sigmas: [1.66666667 1.66666667 1.66666667 1.66666667 1.66666667 1.66666667\n",
      " 1.66666667 1.66666667 1.66666667 1.66666667]\n",
      "alphas: [1.99891218 4.37643825 5.93068887 2.95015123 2.8122093  4.37236723\n",
      " 0.19248865 3.86866586 1.4727749  1.39634561 3.00165063 0.91319127\n",
      " 6.09911343 4.76641513 5.4450183  1.6259058  2.12669142 4.70508058\n",
      " 0.67939315 2.97716564 2.3556301  0.33557629 5.58115402 0.7240567\n",
      " 2.27681362 5.9560086  6.26706637 5.09353385 4.88219529 5.18865998\n",
      " 0.16784409 5.67843846 4.46459125 2.1724376  4.10427766 3.01590017\n",
      " 3.0297009  4.25700682 1.23632986 1.3432906  4.76750869 5.5196918\n",
      " 6.06690912 2.19891607 2.08591981]\n"
     ]
    }
   ],
   "source": [
    "from Individual import *\n",
    "i = Individual(10,5)\n",
    "print(f\"vals: {i.values}\")\n",
    "print(f\"sigmas: {i.sigmas}\")\n",
    "print(f\"alphas: {i.alphas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Individual: copy\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.88730201,  0.15135199, -0.31454241,  0.23589285, -0.23773894,\n",
       "        0.40859426,  0.18496516, -0.23635246,  0.39524466, -0.42087081])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_copy = i.copy_individual()\n",
    "i_copy.values = 54\n",
    "i.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Population\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fun(values):\n",
    "    return sum(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population shape: (n_individuals: 4, n_elements:5)\n",
      "\n",
      "all fitnesses: [ 1.49367244 -0.70474247  0.21192703 -0.48473423]\n",
      "max: 1.4936724420216163\n",
      "min: -0.7047424695529254\n",
      "avg: 0.12903069273029982\n",
      "best: -0.7047424695529254\n"
     ]
    }
   ],
   "source": [
    "from Population import *\n",
    "p = Population(4,5)\n",
    "print(f\"population shape: (n_individuals: {len(p.individuals)}, n_elements:{len(p.individuals[0].values)})\")\n",
    "p.evaluate_fitness(eval_fun)\n",
    "print()\n",
    "print(f'all fitnesses: {p.all_fitnesses()}')\n",
    "print(f'max: {p.max_fitness()}')\n",
    "print(f'min: {p.min_fitness()}')\n",
    "print(f'avg: {p.ave_fitness()}')\n",
    "print(f'best: {p.best_fitness(is_min=True)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mutation: CustomSigma</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before mutation: [-0.88730201  0.15135199 -0.31454241  0.23589285 -0.23773894  0.40859426\n",
      "  0.18496516 -0.23635246  0.39524466 -0.42087081]\n",
      "\n",
      "after mutation: [ 3.17062146 -0.46219466  0.48182469  1.00437101  1.83684483 -1.34247405\n",
      "  2.00793052 -0.6646427   1.2139951  -0.91690557]\n"
     ]
    }
   ],
   "source": [
    "from Mutation import CustomSigma\n",
    "c = CustomSigma()\n",
    "print(f'before mutation: {i.values}')\n",
    "c.mutate(i)\n",
    "print()\n",
    "print(f'after mutation: {i.values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02181104  0.62521499  0.31926973 -0.81382484  0.7655461 ]\n",
      "[-2.64457081  0.88068923  0.04899109 -0.75079611  0.64039191]\n"
     ]
    }
   ],
   "source": [
    "p = Population(10,5)\n",
    "print(p.individuals[2].values)\n",
    "for ind in p.individuals:\n",
    "    c.mutate(ind)\n",
    "print(p.individuals[2].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> \n",
    "Selection: 1 + l\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent fitnesses: [-2.05915331  1.34489338 -0.35188856 -1.73610305  2.20668541 -1.27092444]\n",
      "\n",
      "offspring fitnesses: [ 1.50838121 -0.15744791 -0.86949997  1.13451463  2.74010806  0.78768694\n",
      "  1.0873948   1.5867954   0.69732262  0.12273589  2.11392349  2.90917238\n",
      " -1.65158546 -0.45627999 -0.86447056 -0.21878595 -0.37793988 -0.72584022\n",
      "  0.72213404 -0.34498772  1.4313969   0.09273995  1.76053974 -1.08045281\n",
      "  0.82525874 -3.59486725 -0.4213116  -0.27113003 -0.72362805 -1.15762784]\n",
      "\n",
      "fitnesses after selection: [-3.59486725 -2.05915331 -1.73610305 -1.65158546 -1.27092444 -1.15762784]\n"
     ]
    }
   ],
   "source": [
    "parent = Population(6,10)\n",
    "parent.evaluate_fitness(eval_fun)\n",
    "offspring = Population(30,10)\n",
    "offspring.evaluate_fitness(eval_fun)\n",
    "print(f'parent fitnesses: {parent.all_fitnesses()}')\n",
    "print()\n",
    "print(f'offspring fitnesses: {offspring.all_fitnesses()}')\n",
    "print()\n",
    "from Selection import OnePlusL\n",
    "s = OnePlusL()\n",
    "p = s.select(parent, offspring)\n",
    "print(f'fitnesses after selection: {p.all_fitnesses()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> \n",
    "Selection: 1 , l\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent fitnesses: [ 1.74806686  1.10395752 -4.31769162 -0.31703977  1.54523144  3.15098691]\n",
      "\n",
      "offspring fitnesses: [-1.09739913  1.49965351 -1.19532329  0.1734668   1.32478771 -2.33969922\n",
      "  2.76271817 -1.75194234  1.27301444  0.30838458  2.38117043  1.05989805\n",
      "  0.50248545  1.25234716 -1.93650455 -2.61747848 -0.3387573  -1.89332747\n",
      "  1.62414565 -0.20334909 -2.91736611 -0.33143703  2.86872304 -0.60185459\n",
      " -1.04095981  0.09711158  1.68794823  1.17588846  2.33391624  1.00180479]\n",
      "\n",
      "fitnesses after selection: [-2.91736611 -2.61747848 -2.33969922 -1.93650455 -1.89332747 -1.75194234]\n"
     ]
    }
   ],
   "source": [
    "parent = Population(6,10)\n",
    "parent.evaluate_fitness(eval_fun)\n",
    "offspring = Population(30,10)\n",
    "offspring.evaluate_fitness(eval_fun)\n",
    "print(f'parent fitnesses: {parent.all_fitnesses()}')\n",
    "print()\n",
    "print(f'offspring fitnesses: {offspring.all_fitnesses()}')\n",
    "print()\n",
    "\n",
    "from Selection import OneCommaL\n",
    "s = OneCommaL()\n",
    "p = s.select(parent, offspring)\n",
    "print(f'fitnesses after selection: {p.all_fitnesses()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Recombination: Intermediate\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Population.Population object at 0x7f2ca4181ee0>\n",
      "[ 0.6200462   0.21219599  0.12840492 -0.19562743 -0.23731109 -0.1000117\n",
      " -0.80120904 -0.7488298  -0.37099403 -0.39669866]\n",
      "[ 0.57486226  0.01107044  0.19819138  0.73008386  0.3942891   0.85646642\n",
      "  0.68731574  0.76649631  0.5581316  -0.45557982]\n",
      "[-0.21416953 -0.09620754 -0.05327781  0.11152083  0.03715304  0.56727471\n",
      "  0.20359864  0.95134677  0.73461665 -0.47971659]\n"
     ]
    }
   ],
   "source": [
    "from Recombination import Intermediate\n",
    "parent = Population(6,10)\n",
    "r = Intermediate(3)\n",
    "off = r.recombine(parent)\n",
    "print(off)\n",
    "for i in off.individuals:\n",
    "    print(i.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-19 02:54:22.590511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-19 02:54:22.593786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-19 02:54:22.594115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-19 02:54:22.594573: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-19 02:54:22.595867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-19 02:54:22.596189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-19 02:54:22.596392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-19 02:54:23.129242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-19 02:54:23.129443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-19 02:54:23.129609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-19 02:54:23.129960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3076 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "No file or directory found at tf_model/model/simple_classifier/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mSimpleClassifier\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtf_model/model/simple_classifier/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workdir/EA_ADL/testing/../tf_model/SimpleClassifier.py:32\u001b[0m, in \u001b[0;36mSimpleClassifier.__init__\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(class_names)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_augmentation \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m     18\u001b[0m     [\n\u001b[1;32m     19\u001b[0m         layers\u001b[38;5;241m.\u001b[39mRandomFlip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhorizontal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     ]\n\u001b[1;32m     29\u001b[0m )\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/perc_torch/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/perc_torch/lib/python3.9/site-packages/keras/saving/save.py:204\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    203\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(filepath_str, \u001b[38;5;28mcompile\u001b[39m, options)\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at tf_model/model/simple_classifier/"
     ]
    }
   ],
   "source": [
    "from SimpleClassifier import *\n",
    "model = SimpleClassifier('tf_model/model/simple_classifier/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1816e5b8539f9acb59161f698974e03141d0f020b6322f72e2cfb5eb3657a0af"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
